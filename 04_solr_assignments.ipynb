{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignments nro 3 - Solr\n",
    "\n",
    "## 1\n",
    "\n",
    "Towards the end of the lecture materials *04_solr* there is a piece of Python which indexes Wiki Quotes into Solr. Read the code and make sure you understand its inner workings. Tell me in few sentences - do you find reading such a program difficult? Do you feel you understand it? Do you think you could write a program like this from scratch?\n",
    "\n",
    "## 2\n",
    "\n",
    "1. On the course virtual machine, download and unpack Solr using the instructions given on the lecture. Don't start it yet.\n",
    "2. Choose an arbitrary port number in the 20000-60000 range. That will your port number which you will use to run your own Solr instance.\n",
    "3. Start Solr on your chosen port with `bin/solr -p YOURPORT -f`. If someone else happened to choose same number, that's fine, you will get an error message and try again with a different number.\n",
    "4. Use the ssh port forwarding technique `ssh -Y -L YOURPORT:127.0.0.1:YOURPORT vm0964...` to connect to your solr from your local computer and display the main page of its web interace in your browser. \n",
    "\n",
    "Did you succeed?\n",
    "\n",
    "## 3\n",
    "\n",
    "Use `bin/solr create_core -p YOURPORT -c tweets` to create a core into which you will index some tweets. This is best done from the command line on the course server. It is **extremely** important you use your own selected port number here. If you forget the `-p` parameter, this command will pick the first Solr instance it can find (belonging likely to someone else than you) and will create the core there, causing widespread chaos during our demo session. This is a bit tricky part - because we need to deal with the unusual situation of having many Solr instances on a single server. That is very rarely done in practice, but is important for us.\n",
    "\n",
    "Once you have created the core, head back to the web interface, select your core, and create some fields you would like to index for tweets in the \"Schema\" tab. Maybe a `text` field with field type `text_en` (English text), a `hashtag` field with field type `strings` (not `string`), and maybe a `user` field with field type `string` (not `strings`).\n",
    "\n",
    "Now you are ready for indexing some Twitter data in exercise nro 4. Did you succeed to set it all up? What were the harderst points to understand?\n",
    "\n",
    "## 4\n",
    "\n",
    "For weird reasons, I happen to have a massive collection of tweets mentioning Donald Trump. Let us try to have some fun with it, see what we can find. The tweets are in `/home/ginter/trump_1M.json.gz` on the course machine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
