{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Disclaimer:** some of the material is borrowed with thanks from http://www.cis.lmu.de/~hs/teach/14s/ir/\n",
    "\n",
    "# Boolean model\n",
    "\n",
    "* The Boolean model is arguably the simplest model to\n",
    "  base an information retrieval system on.\n",
    "* Queries are Boolean expressions, e.g., *Caesar* and *Brutus*\n",
    "* The seach engine returns all documents that satisfy the Boolean expression, but there are exceptions:\n",
    "  * anchor text\n",
    "  * page contains variant of query words: morphology, spelling correction, synonyms\n",
    "* No notion of ranking\n",
    "\n",
    "## Term-document matrix\n",
    "\n",
    "* Rows: terms\n",
    "* Columns: document\n",
    "* $M_{ij}=1$ if term *i* present in document *j*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term-document matrix:\n",
      "\n",
      "[[0 0 1 0]\n",
      " [1 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 1 0 0]\n",
      " [1 1 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [1 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]]\n",
      "\n",
      "IDX -> terms mapping:\n",
      "\n",
      "['Nothing', 'This', 'and', 'better', 'example', 'great', 'here', 'is', 'long', 'see', 'silly', 'to']\n",
      "\n",
      "term -> IDX mapping:\n",
      "\n",
      "{'long': 8, 'see': 9, 'This': 1, 'Nothing': 0, 'is': 7, 'silly': 10, 'example': 4, 'better': 3, 'great': 5, 'here': 6, 'and': 2, 'to': 11}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "documents=[\"This is a silly example\",\"A better example\",\"Nothing to see here\",\"This is a great and long example\"]\n",
    "cv=CountVectorizer(lowercase=False,binary=True)\n",
    "print(\"Term-document matrix:\\n\")\n",
    "td_matrix=cv.fit_transform(documents).todense().T   #.T transposes the matrix, sklearn maintains document-term\n",
    "print(td_matrix)\n",
    "print(\"\\nIDX -> terms mapping:\\n\")\n",
    "print(cv.get_feature_names())\n",
    "print(\"\\nterm -> IDX mapping:\\n\")\n",
    "print(cv.vocabulary_) # note the _ at the end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Every row is an *incidence vector* of a term - which documents the term appears in\n",
    "* Boolean retrieval in its simplest form:\n",
    "  * Boolean operations on incidence vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example\n",
      "[[1 1 0 1]]\n",
      "\n",
      "example and great\n",
      "[[0 0 0 1]]\n",
      "\n",
      "not example\n",
      "[[0 0 1 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t2i=cv.vocabulary_\n",
    "print(\"example\")\n",
    "print(td_matrix[t2i[\"example\"]])\n",
    "print()\n",
    "print(\"example and great\")\n",
    "print(td_matrix[t2i[\"example\"]] & td_matrix[t2i[\"great\"]])\n",
    "print()\n",
    "print(\"not example\")\n",
    "print(1-td_matrix[t2i[\"example\"]]) #1-x does the negation in our case\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can piece it all together:\n",
    "\n",
    "* Accept queries like \"( not example or great ) and Nothing\"\n",
    "* Rewrite them into a Python expression\n",
    "* eval() that expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\"example and not Nothing\"\n",
      "Rewritten: td_matrix[t2i[\"example\"]] & 1 - td_matrix[t2i[\"Nothing\"]]\n",
      "Matching: [[1 1 0 1]]\n",
      "\n",
      "Query:\"not example or great\"\n",
      "Rewritten: 1 - td_matrix[t2i[\"example\"]] | td_matrix[t2i[\"great\"]]\n",
      "Matching: [[0 0 1 1]]\n",
      "\n",
      "Query:\"( not example or great ) and Nothing\"\n",
      "Rewritten: ( 1 - td_matrix[t2i[\"example\"]] | td_matrix[t2i[\"great\"]] ) & td_matrix[t2i[\"Nothing\"]]\n",
      "Matching: [[0 0 1 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Operators and, or, not become &, |, 1 -\n",
    "# Parentheses are left untouched\n",
    "# Everything else interpreted as a term and fed through td_matrix[t2i[\"...\"]]\n",
    "\n",
    "d={\"and\":\"&\",\"or\":\"|\",\"not\":\"1 -\",\"(\":\"(\",\")\":\")\"} # operator replacements\n",
    "def rew_token(t):\n",
    "    return d.get(t,'td_matrix[t2i[\"{}\"]]'.format(t))\n",
    "\n",
    "def rew_query(query): #rewrite every token in the query\n",
    "    return \" \".join(rew_token(t) for t in query.split())\n",
    "\n",
    "def test_query(query):\n",
    "    print(\"Query:\\\"\"+query+\"\\\"\")\n",
    "    print(\"Rewritten:\",rew_query(query))\n",
    "    print(\"Matching:\",eval(rew_query(query)))\n",
    "    print()\n",
    "\n",
    "test_query(\"example and not Nothing\")\n",
    "test_query(\"not example or great\")\n",
    "test_query(\"( not example or great ) and Nothing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\"not awordwhichdoesnotexist\"\n",
      "Rewritten: 1 - td_matrix[t2i[\"awordwhichdoesnotexist\"]].todense()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-122-69ec74878d51>\", line 5, in <module>\n",
      "    test_query(\"not awordwhichdoesnotexist\") #should match all documents\n",
      "  File \"<ipython-input-116-41857662fdc6>\", line 15, in test_query\n",
      "    print(\"Matching:\",eval(rew_query(query)))\n",
      "  File \"<string>\", line 1, in <module>\n",
      "KeyError: 'awordwhichdoesnotexist'\n"
     ]
    }
   ],
   "source": [
    "# Should match all documents, but crashes instead\n",
    "# This one you will fix as an exercise\n",
    "import traceback\n",
    "try:\n",
    "    test_query(\"not awordwhichdoesnotexist\") #should match all documents\n",
    "except:\n",
    "    traceback.print_exc() #I only need to do this because of IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We now have a rudimentary boolean IR system\n",
    "* It is not that great but ready in < 10 lines of code in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size constraints\n",
    "\n",
    "* Term-document matrix is vocabulary size times document set size\n",
    "* 1M documents, each 1000 words\n",
    "* 1,000,000 x 1,000 = 1,000,000,000 words of running text\n",
    "* 6 bytes per word -> ~6GB in size\n",
    "* Assume 500,000 unique terms\n",
    "* Term-document matrix has 1,000,000 x 500,000 / 8 / 1024 / 1024 / 1024 -> ~60GB\n",
    "* 60GB of space to index a collection of 6GB of text!\n",
    "* 480GB if we were to use 1B integers to remember the 0/1 values\n",
    "* ...but most of this are zeros...\n",
    "\n",
    "## Sparse representation\n",
    "\n",
    "* Only remember the non-zero entries\n",
    "* For every term, remember a (usually sorted) list of documents in which it appears\n",
    "* This is the famous **inverted index**\n",
    "* Scipy sparse formats: https://docs.scipy.org/doc/scipy-0.18.1/reference/sparse.html\n",
    "  * *CSC* for every column remember the list of rows\n",
    "  * *CSR* for every row remember the list of columns\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit's document-term matrix:\n",
      "  (0, 1)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 6)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 7)\t1\n",
      "  (3, 4)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 8)\t1\n",
      "\n",
      "Transposed: (note incorrect sort)\n",
      "  (1, 0)\t1\n",
      "  (7, 0)\t1\n",
      "  (10, 0)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 1)\t1\n",
      "  (3, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (11, 2)\t1\n",
      "  (9, 2)\t1\n",
      "  (6, 2)\t1\n",
      "  (1, 3)\t1\n",
      "  (7, 3)\t1\n",
      "  (4, 3)\t1\n",
      "  (5, 3)\t1\n",
      "  (2, 3)\t1\n",
      "  (8, 3)\t1\n",
      "\n",
      "Transposed, and in the correct sparse format:\n",
      "  (0, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 1)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "  (5, 3)\t1\n",
      "  (6, 2)\t1\n",
      "  (7, 0)\t1\n",
      "  (7, 3)\t1\n",
      "  (8, 3)\t1\n",
      "  (9, 2)\t1\n",
      "  (10, 0)\t1\n",
      "  (11, 2)\t1\n"
     ]
    }
   ],
   "source": [
    "documents=[\"This is a silly example\",\"A better example\",\"Nothing to see here\",\"This is a great and long example\"]\n",
    "cv=CountVectorizer(lowercase=False,binary=True)\n",
    "# Exact same code as above, but I removed the .todense()\n",
    "td_matrix=cv.fit_transform(documents)\n",
    "print(\"scikit's document-term matrix:\")\n",
    "print(td_matrix)\n",
    "print()\n",
    "print(\"Transposed: (note incorrect sort)\")\n",
    "print(td_matrix.T)\n",
    "print()\n",
    "print(\"Transposed, and in the correct sparse format:\")\n",
    "print(td_matrix.T.tocsr())\n",
    "td_matrix=td_matrix.T.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\"example and not Nothing\"\n",
      "Rewritten: td_matrix[t2i[\"example\"]].todense() & 1 - td_matrix[t2i[\"Nothing\"]].todense()\n",
      "Matching: [[1 1 0 1]]\n",
      "\n",
      "Query:\"( not example or great ) and Nothing\"\n",
      "Rewritten: ( 1 - td_matrix[t2i[\"example\"]].todense() | td_matrix[t2i[\"great\"]].todense() ) & td_matrix[t2i[\"Nothing\"]].todense()\n",
      "Matching: [[0 0 1 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The sparse representations do not allow many of the necessary operations, so we need\n",
    "# to make the rows dense, once we retrieve them, not a huge deal for our toy examples\n",
    "def rew_token(t):\n",
    "    return d.get(t,'td_matrix[t2i[\"{}\"]].todense()'.format(t))\n",
    "\n",
    "test_query(\"example and not Nothing\")\n",
    "test_query(\"( not example or great ) and Nothing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean retrieval (cont.)\n",
    "\n",
    "* The code above needs `.todense()` to perform the *and / or / not* arithmetics -> inefficient, but simple\n",
    "* Other option - make sure the lists of documents are sorted\n",
    "* AND - intersection of two sorted lists\n",
    "  * Walk the lists (I'll show on the lecture how - it's rather obvious anyway)\n",
    "  * Linear complexity in terms of number of documents\n",
    "  * A good exercise - write a function which takes two lists like those above, and computes their intersection as a new list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents for 'example'\n",
      "[0 1 3]\n",
      "\n",
      "Documents for 'great'\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "print(\"Documents for 'example'\")\n",
    "print(td_matrix[t2i[\"example\"]].nonzero()[1])\n",
    "print()\n",
    "print(\"Documents for 'great'\")\n",
    "print(td_matrix[t2i[\"great\"]].nonzero()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase and proximity queries\n",
    "\n",
    "* *\"Stanford university\"* - not the same thing as *Stanford AND university*\n",
    "* The basic inverted index of no help\n",
    "\n",
    "## biword index\n",
    "\n",
    "* Index all word bigrams\n",
    "* \"Stanford university\" becomes a term\n",
    "* \"to be or not to be\" -> \"to be\" and \"be or\" and \"or not\" and \"not to\" + postprocessing\n",
    "* Not a great solution:\n",
    "  * Massive waste of space: blows up the index size quadratically\n",
    "  * Needs postprocessing to weed out the false hits\n",
    "\n",
    "## positional index\n",
    "\n",
    "* For every term, and every document, remember a list of the positions, not just \"1\"\n",
    "* A modification of the sorted list intersection algorithm to answer the query\n",
    "* Also allows proximity queries \"X within N words from Y\"\n",
    "* Quite heavy computationally\n",
    "\n",
    "## combined index\n",
    "\n",
    "* Most common biwords indexed directly\n",
    "* Rest solved with positional indexing\n",
    "* Compromise between the two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result ranking\n",
    "\n",
    "* Obviously useful for large document collections\n",
    "* Come up with a number describing the fit of a document to a query\n",
    "* Return top-N documents\n",
    "* Basic observations:\n",
    "  * The more query terms hit, the more relevant the document is\n",
    "  * The more times the query terms hit in the document, the more relevant the document is\n",
    "  * Rare terms are more informative than common terms\n",
    "* Firstly, we don't want to store 0/1, we want to store the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0]\n",
      " [1 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 1 0 0]\n",
      " [1 1 0 2]\n",
      " [0 0 0 1]\n",
      " [0 0 3 0]\n",
      " [1 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 2 0]\n",
      " [0 0 1 0]\n",
      " [3 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "documents=[\"This is a silly silly silly example\",\"A better example\",\"Nothing to see here nor here nor here\",\"This is a great example and a long example too\"]\n",
    "cv=CountVectorizer(lowercase=False)\n",
    "# Exact same code as above, but now I also removed binary=True\n",
    "td_matrix=cv.fit_transform(documents)\n",
    "t2i=cv.vocabulary_\n",
    "td_matrix=td_matrix.T.tocsr()\n",
    "print(td_matrix.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sum up the counts across query hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents for 'example' and 'better'\n",
      "Hits:\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t2\n",
      "  (0, 3)\t2\n",
      "Documents: [0 1 3]\n",
      "Scores: [1 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Documents for 'example' and 'better'\")\n",
    "hits=td_matrix[t2i[\"example\"]]+td_matrix[t2i[\"better\"]]\n",
    "print(\"Hits:\",hits,sep=\"\\n\")\n",
    "print(\"Documents:\", hits.nonzero()[1])\n",
    "print(\"Scores:\", hits[hits.nonzero()].A1) #A1 returns itself as flat array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we can sort on scores and get an order on documents\n",
    "* Now a document with 2x example hits equally well as document with 1x example and 1x better\n",
    "* Maybe not optimal?\n",
    "* A document with a term occurring 10x is more important, but not ten times so\n",
    "* Usual solution: squeeze the counts through log or similar function (done already at index time)\n",
    "  * $1+log_{10}(tf)$ is a typical formula used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just to check we get same numbers as with CountVectorizer:\n",
      "[[ 0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 1.  1.  0.  2.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  3.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  2.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 3.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "Just to check we get same numbers as with CountVectorizer:\n",
      "[[ 0.          0.          1.          0.        ]\n",
      " [ 1.          0.          0.          1.        ]\n",
      " [ 0.          0.          0.          1.        ]\n",
      " [ 0.          1.          0.          0.        ]\n",
      " [ 1.          1.          0.          1.69314718]\n",
      " [ 0.          0.          0.          1.        ]\n",
      " [ 0.          0.          2.09861229  0.        ]\n",
      " [ 1.          0.          0.          1.        ]\n",
      " [ 0.          0.          0.          1.        ]\n",
      " [ 0.          0.          1.69314718  0.        ]\n",
      " [ 0.          0.          1.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.        ]\n",
      " [ 0.          0.          1.          0.        ]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Switch from CountVectorizer to TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Parameters with which TfidfVectorizer does same thing as CountVectorizer\n",
    "tfv=TfidfVectorizer(lowercase=False,sublinear_tf=False,use_idf=False,norm=None)\n",
    "td_matrix=tfv.fit_transform(documents)\n",
    "t2i=cv.vocabulary_\n",
    "td_matrix=td_matrix.T.tocsr()\n",
    "print(\"Just to check we get same numbers as with CountVectorizer:\")\n",
    "print(td_matrix.todense())\n",
    "\n",
    "# Turn log-squeeze on\n",
    "tfv=TfidfVectorizer(lowercase=False,sublinear_tf=True,use_idf=False,norm=None)\n",
    "td_matrix=tfv.fit_transform(documents)\n",
    "t2i=cv.vocabulary_\n",
    "td_matrix=td_matrix.T.tocsr()\n",
    "print(\"Just to check we get same numbers as with CountVectorizer:\")\n",
    "print(td_matrix.todense())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* and now the *example* and *better* document should rank above the *2x example* document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents for 'example' and 'better'\n",
      "Hits:\n",
      "  (0, 0)\t1.0\n",
      "  (0, 1)\t2.0\n",
      "  (0, 3)\t1.69314718056\n",
      "Documents: [0 1 3]\n",
      "Scores: [ 1.          2.          1.69314718]\n"
     ]
    }
   ],
   "source": [
    "print(\"Documents for 'example' and 'better'\")\n",
    "hits=td_matrix[t2i[\"example\"]]+td_matrix[t2i[\"better\"]]\n",
    "print(\"Hits:\",hits,sep=\"\\n\")\n",
    "print(\"Documents:\", hits.nonzero()[1])\n",
    "print(\"Scores:\", hits[hits.nonzero()].A1) #A1 returns itself as flat array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informativeness of terms\n",
    "\n",
    "* Not all words are equally informative\n",
    "* Rare words are clearly much more informative than common ones\n",
    "* The query *\"jabberwocky movie cast\"* should put more weight on *jabberwocky*\n",
    "* What we want:\n",
    "  * High positive weight for rare terms\n",
    "  * Low positive weight for common terms\n",
    "* Typical way: IDF *inverse document frequency*\n",
    "  * df_t is the *document frequency* of *t* - number of documents *t* appear in\n",
    "  * $IDF_t=\\frac{N}{df_t}$ inverse document frequency of *t*\n",
    "  * Usually one would squeeze this through log so\n",
    "  * $IDF_t=log_{10}(\\frac{N}{df_t})$\n",
    "\n",
    "## Tf.Idf\n",
    "\n",
    "* An extremely common weighting scheme in IR\n",
    "* Product of term's tf (log-squeezed) with the term's idf (log-squeezed)\n",
    "* Gives a score of that term's hit in a given document\n",
    "  * $(1+log_{10}tf_t)\\cdot log_{10}\\frac{N}{df_t}$\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just to check we get same numbers as with CountVectorizer:\n",
      "[[ 0.          0.          1.91629073  0.        ]\n",
      " [ 1.51082562  0.          0.          1.51082562]\n",
      " [ 0.          0.          0.          1.91629073]\n",
      " [ 0.          1.91629073  0.          0.        ]\n",
      " [ 1.22314355  1.22314355  0.          2.07096206]\n",
      " [ 0.          0.          0.          1.91629073]\n",
      " [ 0.          0.          4.02155128  0.        ]\n",
      " [ 1.51082562  0.          0.          1.51082562]\n",
      " [ 0.          0.          0.          1.91629073]\n",
      " [ 0.          0.          3.24456225  0.        ]\n",
      " [ 0.          0.          1.91629073  0.        ]\n",
      " [ 4.02155128  0.          0.          0.        ]\n",
      " [ 0.          0.          1.91629073  0.        ]\n",
      " [ 0.          0.          0.          1.91629073]]\n"
     ]
    }
   ],
   "source": [
    "# same as above, but use_idf=True\n",
    "tfv=TfidfVectorizer(lowercase=False,sublinear_tf=True,use_idf=True,norm=None)\n",
    "td_matrix=tfv.fit_transform(documents)\n",
    "t2i=cv.vocabulary_\n",
    "td_matrix=td_matrix.T.tocsr()\n",
    "print(\"Just to check we get same numbers as with CountVectorizer:\")\n",
    "print(td_matrix.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents for 'example' and 'better' with full tf.idf weighting\n",
      "Hits:\n",
      "  (0, 0)\t1.22314355131\n",
      "  (0, 1)\t3.13943428319\n",
      "  (0, 3)\t2.07096205533\n",
      "Documents: [0 1 3]\n",
      "Scores: [ 1.22314355  3.13943428  2.07096206]\n"
     ]
    }
   ],
   "source": [
    "print(\"Documents for 'example' and 'better' with full tf.idf weighting\")\n",
    "hits=td_matrix[t2i[\"example\"]]+td_matrix[t2i[\"better\"]]\n",
    "print(\"Hits:\",hits,sep=\"\\n\")\n",
    "print(\"Documents:\", hits.nonzero()[1])\n",
    "print(\"Scores:\", hits[hits.nonzero()].A1) #A1 returns itself as flat array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector-space model\n",
    "\n",
    "* So far we looked at term vectors (rows of the term-document matrix)\n",
    "* We could also think about document vectors (columns of the term-document matrix)\n",
    "* Documents are vectors in a high-dimensional space, terms are the dimensions\n",
    "* Document vectors very high-dimensional but very very sparse\n",
    "* Same for queries - queries can also be seen as vectors in a high-dimensional space\n",
    "* Search:\n",
    "  * Similarity between query vector and document vector\n",
    "  \n",
    "## Similarity measures\n",
    "\n",
    "* similarity -> negative distance\n",
    "* Eucledian distance -> affected by vector length\n",
    "* Cosine similarity -> cosine of the angle between query and document vectors\n",
    "  * 1 for total similarity (angle 0)\n",
    "  * -1 for complete opposite\n",
    "  * we only have positive numbers in our vectors, so we are on the [0,1] scale not [-1,1]\n",
    "  * not sensitive to length\n",
    "  * incredibly easy to compute!\n",
    "  * $cos(u,v)=\\frac{u\\cdot v}{||u||\\cdot ||v||}=\\frac{\\sum_i v_i\\cdot u_i}{\\sqrt{\\sum_i u_i^2}\\sqrt{\\sum_i v_i^2}}$\n",
    "  * dot-product of normalized vectors - just multiply the numbers together, really\n",
    "  \n",
    "## Weighting schemes - document, query\n",
    "\n",
    "* Now we can apply different weighting to documents and queries\n",
    "* Typical choice:\n",
    "  * document: log tf, no idf, length-normalized\n",
    "  * query: log tf, log idf, length-normalized\n",
    "  * cosine similarity\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
