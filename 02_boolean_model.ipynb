{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Disclaimer:** some of the material is borrowed with thanks from http://www.cis.lmu.de/~hs/teach/14s/ir/\n",
    "\n",
    "# Boolean model\n",
    "\n",
    "* The Boolean model is arguably the simplest model to\n",
    "  base an information retrieval system on.\n",
    "* Queries are Boolean expressions, e.g., *Caesar* and *Brutus*\n",
    "* The seach engine returns all documents that satisfy the Boolean expression, but there are exceptions:\n",
    "  * anchor text\n",
    "  * page contains variant of query words: morphology, spelling correction, synonyms\n",
    "* No notion of ranking\n",
    "\n",
    "## Term-document matrix\n",
    "\n",
    "* Rows: terms\n",
    "* Columns: document\n",
    "* $M_{ij}=1$ if term *i* present in document *j*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term-document matrix:\n",
      "\n",
      "[[0 0 1 0]\n",
      " [1 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 1 0 0]\n",
      " [1 1 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [1 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]]\n",
      "\n",
      "IDX -> terms mapping:\n",
      "\n",
      "['Nothing', 'This', 'and', 'better', 'example', 'great', 'here', 'is', 'long', 'see', 'silly', 'to']\n",
      "\n",
      "term -> IDX mapping:\n",
      "\n",
      "{'long': 8, 'see': 9, 'This': 1, 'Nothing': 0, 'is': 7, 'silly': 10, 'example': 4, 'better': 3, 'great': 5, 'here': 6, 'and': 2, 'to': 11}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "documents=[\"This is a silly example\",\"A better example\",\"Nothing to see here\",\"This is a great and long example\"]\n",
    "cv=CountVectorizer(lowercase=False,binary=True)\n",
    "print(\"Term-document matrix:\\n\")\n",
    "td_matrix=cv.fit_transform(documents).todense().T   #.T transposes the matrix, sklearn maintains document-term\n",
    "print(td_matrix)\n",
    "print(\"\\nIDX -> terms mapping:\\n\")\n",
    "print(cv.get_feature_names())\n",
    "print(\"\\nterm -> IDX mapping:\\n\")\n",
    "print(cv.vocabulary_) # note the _ at the end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Every row is an *incidence vector* of a term - which documents the term appears in\n",
    "* Boolean retrieval in its simplest form:\n",
    "  * Boolean operations on incidence vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example\n",
      "[[1 1 0 1]]\n",
      "\n",
      "example and great\n",
      "[[0 0 0 1]]\n",
      "\n",
      "not example\n",
      "[[0 0 1 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t2i=cv.vocabulary_\n",
    "print(\"example\")\n",
    "print(td_matrix[t2i[\"example\"]])\n",
    "print()\n",
    "print(\"example and great\")\n",
    "print(td_matrix[t2i[\"example\"]] & td_matrix[t2i[\"great\"]])\n",
    "print()\n",
    "print(\"not example\")\n",
    "print(1-td_matrix[t2i[\"example\"]]) #1-x does the negation in our case\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can piece it all together:\n",
    "\n",
    "* Accept queries like \"( not example or great ) and Nothing\"\n",
    "* Rewrite them into a Python expression\n",
    "* eval() that expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\"example and not Nothing\"\n",
      "Rewritten: td_matrix[t2i[\"example\"]] & 1 - td_matrix[t2i[\"Nothing\"]]\n",
      "Matching: [[1 1 0 1]]\n",
      "\n",
      "Query:\"not example or great\"\n",
      "Rewritten: 1 - td_matrix[t2i[\"example\"]] | td_matrix[t2i[\"great\"]]\n",
      "Matching: [[0 0 1 1]]\n",
      "\n",
      "Query:\"( not example or great ) and Nothing\"\n",
      "Rewritten: ( 1 - td_matrix[t2i[\"example\"]] | td_matrix[t2i[\"great\"]] ) & td_matrix[t2i[\"Nothing\"]]\n",
      "Matching: [[0 0 1 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Operators and, or, not become &, |, 1 -\n",
    "# Parentheses are left untouched\n",
    "# Everything else interpreted as a term and fed through td_matrix[t2i[\"...\"]]\n",
    "\n",
    "d={\"and\":\"&\",\"or\":\"|\",\"not\":\"1 -\",\"(\":\"(\",\")\":\")\"} # operator replacements\n",
    "def rew_token(t):\n",
    "    return d.get(t,'td_matrix[t2i[\"{}\"]]'.format(t))\n",
    "\n",
    "def rew_query(query): #rewrite every token in the query\n",
    "    return \" \".join(rew_token(t) for t in query.split())\n",
    "\n",
    "def test_query(query):\n",
    "    print(\"Query:\\\"\"+query+\"\\\"\")\n",
    "    print(\"Rewritten:\",rew_query(query))\n",
    "    print(\"Matching:\",eval(rew_query(query)))\n",
    "    print()\n",
    "\n",
    "test_query(\"example and not Nothing\")\n",
    "test_query(\"not example or great\")\n",
    "test_query(\"( not example or great ) and Nothing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\"not awordwhichdoesnotexist\"\n",
      "Rewritten: 1 - td_matrix[t2i[\"awordwhichdoesnotexist\"]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-117-69ec74878d51>\", line 5, in <module>\n",
      "    test_query(\"not awordwhichdoesnotexist\") #should match all documents\n",
      "  File \"<ipython-input-116-41857662fdc6>\", line 15, in test_query\n",
      "    print(\"Matching:\",eval(rew_query(query)))\n",
      "  File \"<string>\", line 1, in <module>\n",
      "KeyError: 'awordwhichdoesnotexist'\n"
     ]
    }
   ],
   "source": [
    "# Should match all documents, but crashes instead\n",
    "# This one you will fix as an exercise\n",
    "import traceback\n",
    "try:\n",
    "    test_query(\"not awordwhichdoesnotexist\") #should match all documents\n",
    "except:\n",
    "    traceback.print_exc() #I only need to do this because of IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We now have a rudimentary boolean IR system\n",
    "* It is not that great but ready in < 10 lines of code in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size constraints\n",
    "\n",
    "* Term-document matrix is vocabulary size times document set size\n",
    "* 1M documents, each 1000 words\n",
    "* 1,000,000 x 1,000 = 1,000,000,000 words of running text\n",
    "* 6 bytes per word -> ~6GB in size\n",
    "* Assume 500,000 unique terms\n",
    "* Term-document matrix has 1,000,000 x 500,000 / 8 / 1024 / 1024 / 1024 -> ~60GB\n",
    "* 60GB of space to index a collection of 6GB of text!\n",
    "* 480GB if we were to use 1B integers to remember the 0/1 values\n",
    "* ...but most of this are zeros...\n",
    "\n",
    "## Sparse representation\n",
    "\n",
    "* Only remember the non-zero entries\n",
    "* For every term, remember a (usually sorted) list of documents in which it appears\n",
    "* This is the famous **inverted index**\n",
    "* Scipy sparse formats: https://docs.scipy.org/doc/scipy-0.18.1/reference/sparse.html\n",
    "  * *CSC* for every column remember the list of rows\n",
    "  * *CSR* for every row remember the list of columns\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit's document-term matrix:\n",
      "  (0, 1)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 6)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 7)\t1\n",
      "  (3, 4)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 8)\t1\n",
      "\n",
      "Transposed: (note incorrect sort)\n",
      "  (1, 0)\t1\n",
      "  (7, 0)\t1\n",
      "  (10, 0)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 1)\t1\n",
      "  (3, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (11, 2)\t1\n",
      "  (9, 2)\t1\n",
      "  (6, 2)\t1\n",
      "  (1, 3)\t1\n",
      "  (7, 3)\t1\n",
      "  (4, 3)\t1\n",
      "  (5, 3)\t1\n",
      "  (2, 3)\t1\n",
      "  (8, 3)\t1\n",
      "\n",
      "Transposed, and in the correct sparse format:\n",
      "  (0, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 1)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "  (5, 3)\t1\n",
      "  (6, 2)\t1\n",
      "  (7, 0)\t1\n",
      "  (7, 3)\t1\n",
      "  (8, 3)\t1\n",
      "  (9, 2)\t1\n",
      "  (10, 0)\t1\n",
      "  (11, 2)\t1\n"
     ]
    }
   ],
   "source": [
    "documents=[\"This is a silly example\",\"A better example\",\"Nothing to see here\",\"This is a great and long example\"]\n",
    "cv=CountVectorizer(lowercase=False,binary=True)\n",
    "# Exact same code as above, but I removed the .todense()\n",
    "td_matrix=cv.fit_transform(documents)\n",
    "print(\"scikit's document-term matrix:\")\n",
    "print(td_matrix)\n",
    "print()\n",
    "print(\"Transposed: (note incorrect sort)\")\n",
    "print(td_matrix.T)\n",
    "print()\n",
    "print(\"Transposed, and in the correct sparse format:\")\n",
    "print(td_matrix.T.tocsr())\n",
    "td_matrix=td_matrix.T.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\"example and not Nothing\"\n",
      "Rewritten: td_matrix[t2i[\"example\"]].todense() & 1 - td_matrix[t2i[\"Nothing\"]].todense()\n",
      "Matching: [[1 1 0 1]]\n",
      "\n",
      "Query:\"( not example or great ) and Nothing\"\n",
      "Rewritten: ( 1 - td_matrix[t2i[\"example\"]].todense() | td_matrix[t2i[\"great\"]].todense() ) & td_matrix[t2i[\"Nothing\"]].todense()\n",
      "Matching: [[0 0 1 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The sparse representations do not allow many of the necessary operations, so we need\n",
    "# to make the rows dense, once we retrieve them, not a huge deal for our toy examples\n",
    "def rew_token(t):\n",
    "    return d.get(t,'td_matrix[t2i[\"{}\"]].todense()'.format(t))\n",
    "\n",
    "test_query(\"example and not Nothing\")\n",
    "test_query(\"( not example or great ) and Nothing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean retrieval (cont.)\n",
    "\n",
    "* The code above needs `.todense()` to perform the *and / or / not* arithmetics -> inefficient, but simple\n",
    "* Other option - make sure the lists of documents are sorted\n",
    "* AND - intersection of two sorted lists\n",
    "  * Walk the lists (I'll show on the lecture how - it's rather obvious anyway)\n",
    "  * Linear complexity in terms of number of documents\n",
    "  * A good exercise - write a function which takes two lists like those above, and computes their intersection as a new list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents for 'example'\n",
      "[0 1 3]\n",
      "\n",
      "Documents for 'great'\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "print(\"Documents for 'example'\")\n",
    "print(td_matrix[t2i[\"example\"]].nonzero()[1])\n",
    "print()\n",
    "print(\"Documents for 'great'\")\n",
    "print(td_matrix[t2i[\"great\"]].nonzero()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase and proximity queries\n",
    "\n",
    "* *\"Stanford university\"* - not the same thing as *Stanford AND university*\n",
    "* The basic inverted index of no help\n",
    "\n",
    "## biword index\n",
    "\n",
    "* Index all word bigrams\n",
    "* \"Stanford university\" becomes a term\n",
    "* \"to be or not to be\" -> \"to be\" and \"be or\" and \"or not\" and \"not to\" + postprocessing\n",
    "* Not a great solution:\n",
    "  * Massive waste of space: blows up the index size quadratically\n",
    "  * Needs postprocessing to weed out the false hits\n",
    "\n",
    "## positional index\n",
    "\n",
    "* For every term, and every document, remember a list of the positions, not just \"1\"\n",
    "* A modification of the sorted list intersection algorithm to answer the query\n",
    "* Also allows proximity queries \"X within N words from Y\"\n",
    "* Quite heavy computationally\n",
    "\n",
    "## combined index\n",
    "\n",
    "* Most common biwords indexed directly\n",
    "* Rest solved with positional indexing\n",
    "* Compromise between the two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result ranking\n",
    "\n",
    "* Obviously useful for large document collections\n",
    "* Come up with a number describing the fit of a document to a query\n",
    "* Return top-N documents\n",
    "* Basic observations:\n",
    "  * The more query terms hit, the more relevant the document is\n",
    "  * The more times the query terms hit in the document, the more relevant the document is\n",
    "  * Rare terms are more informative than common terms\n",
    "* Firstly, we don't want to store 0/1, we want to store the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0]\n",
      " [1 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 1 0 0]\n",
      " [1 1 0 2]\n",
      " [0 0 0 1]\n",
      " [0 0 3 0]\n",
      " [1 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 2 0]\n",
      " [0 0 1 0]\n",
      " [3 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "documents=[\"This is a silly silly silly example\",\"A better example\",\"Nothing to see here nor here nor here\",\"This is a great example and a long example too\"]\n",
    "cv=CountVectorizer(lowercase=False)\n",
    "# Exact same code as above, but now I also removed binary=True\n",
    "td_matrix=cv.fit_transform(documents)\n",
    "t2i=cv.vocabulary_\n",
    "td_matrix=td_matrix.T.tocsr()\n",
    "print(td_matrix.todense())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
