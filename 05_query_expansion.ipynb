{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Query expansion\n",
    "\n",
    "Reformulate or expand the query in order to find more and better results\n",
    "\n",
    "1. Morphological\n",
    "   * Find also different inflections of the search word (especially important for languages like Finnish)\n",
    "   * If our search word is 'koiralle', maybe we should also return documents containing koira, koiran, koiraa, koiralla, koiralta, koirilla, koirilta, koirille...\n",
    "   * Stemming or lemmatization\n",
    "2. Synonyms or related terms\n",
    "   * Expand the search with synonyms or other related terms\n",
    "3. Spelling errors\n",
    "   * If a word is mistyped in the search, it's unlikely we will find good results --> spelling correction or 'Did you mean'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Morphology\n",
    "\n",
    "### Stemming\n",
    "\n",
    "- Reduce inflected word to a word stem by dropping all inflection affixes: open, opens, opening, opener --> open\n",
    "- Word stem: the part of the word that is common to all its inflected variants (not necessary same as the base form)\n",
    "- koira, koiran, koiria --> stem is koir\n",
    "- By default, Solr uses stemming in text fileds, text_en uses English stemming model and text_fi uses Finnish stemming model\n",
    "- Snowball stemmer: removes known affixes from words and only the stem should stay\n",
    "- bit too brute force for Finnish, e.g. removes 'na' from 'peruna' because -na is a known suffix for essives\n",
    "- Solr also has other, less aggressive stemmers...\n",
    "\n",
    "### Lemmatization\n",
    "\n",
    "- Determine the base form of the word\n",
    "- Maybe not a big deal in English? ([UDPipe](http://lindat.mff.cuni.cz/services/udpipe/run.php) lemma accuracy 97%)\n",
    "- ...but more difficult problem in Finnish, UDPipe lemma accuracy 86.8%, but can be improved if rule-based morphological analyzer (Omorfi) is included\n",
    "- Solr does not have ready-made lemmatizers, but one can include own lemmatizer\n",
    "\n",
    "### ...in Solr\n",
    "\n",
    "* **Where** does this happen? How do we tell Solr to do all this?\n",
    "* When adding a field to Solr you are asked for `field type`, which pretty much tells Solr what to do with that field\n",
    "* These come from `solr/server/solr/CORENAME/conf/managed-schema` where much of the config of a single core is\n",
    "* Reasonable defaults which you can change of course\n",
    "* Here's `text_fi`\n",
    "  1. Tokenize\n",
    "  2. Lowercase\n",
    "  3. Apply stop word list\n",
    "  4. Stem\n",
    "\n",
    "```\n",
    "  <fieldType name=\"text_fi\" class=\"solr.TextField\" positionIncrementGap=\"100\">\n",
    "    <analyzer>\n",
    "      <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n",
    "      <filter class=\"solr.LowerCaseFilterFactory\"/>\n",
    "      <filter class=\"solr.StopFilterFactory\" format=\"snowball\" words=\"lang/stopwords_fi.txt\" ignoreCase=\"true\"/>\n",
    "      <filter class=\"solr.SnowballPorterFilterFactory\" language=\"Finnish\"/>\n",
    "    </analyzer>\n",
    "  </fieldType>\n",
    "```\n",
    "\n",
    "* These (and many others) are documented [here](https://cwiki.apache.org/confluence/display/solr/Filter+Descriptions#FilterDescriptions-SynonymFilter)\n",
    "* Change schema: edit `managed-schema` and restart Solr or at least reload core\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Synonym expansion\n",
    "\n",
    "### WordNet\n",
    "\n",
    "- Lexical database where words are grouped into synonym sets (synsets), and other types of hierarchies (antonyms, hyponyms, hyperonyms)\n",
    "- English: http://wordnetweb.princeton.edu/perl/webwn\n",
    "- Finnish: http://www.ling.helsinki.fi/cgi-bin/fiwn/search\n",
    "\n",
    "- Also available as a python NLTK package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fire: [Synset('fire.n.01'), Synset('fire.n.02'), Synset('fire.n.03'), Synset('fire.n.04'), Synset('fire.n.05'), Synset('ardor.n.03'), Synset('fire.n.07'), Synset('fire.n.08'), Synset('fire.n.09'), Synset('open_fire.v.01'), Synset('fire.v.02'), Synset('fire.v.03'), Synset('displace.v.03'), Synset('fire.v.05'), Synset('fire.v.06'), Synset('arouse.v.01'), Synset('burn.v.01'), Synset('fuel.v.02')]\n",
      "fire as verb [Synset('open_fire.v.01'), Synset('fire.v.02'), Synset('fire.v.03'), Synset('displace.v.03'), Synset('fire.v.05'), Synset('fire.v.06'), Synset('arouse.v.01'), Synset('burn.v.01'), Synset('fuel.v.02')]\n",
      "Definition of first fire: Synset('fire.n.01') the event of something burning (often destructive)\n",
      "Definition of first fire as verb: Synset('open_fire.v.01') start firing a weapon\n",
      "Lemmas ['open_fire', 'fire'] \n",
      "\n",
      "Languages available: ['eng', 'als', 'arb', 'bul', 'cat', 'cmn', 'dan', 'ell', 'eus', 'fas', 'fin', 'fra', 'glg', 'heb', 'hrv', 'ind', 'ita', 'jpn', 'nno', 'nob', 'pol', 'por', 'qcn', 'slv', 'spa', 'swe', 'tha', 'zsm'] \n",
      "\n",
      "Finnish lemmas: ['ampua', 'avata_tuli'] \n",
      "\n",
      "Looked up in Finnish ['tuli', 'tulitus'] \n",
      "\n",
      "First few lemmas ['rosa_chinensis', 'skip-bomb', 'short_subject', 'caespitose', 'brick_trowel']\n",
      "Total words English: 147306 \n",
      "\n",
      "First few lemmas in Finnish ['jkn_vallassa_oleminen', 'töhritty', 'ahdistelu', 'avajaisten_johdosta', 'eläketili']\n",
      "Total words Finnish: 129839\n"
     ]
    }
   ],
   "source": [
    "#import nltk ; nltk.download() # download wordnet and other nltk material (get at least omw and wordnet in corpora)\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "\n",
    "print(\"fire:\",wn.synsets(\"fire\")) # all synsets for a word\n",
    "print(\"fire as verb\", wn.synsets(\"fire\", pos=wn.VERB)) # define part-of-speech\n",
    "\n",
    "# synset definitions\n",
    "print(\"Definition of first fire:\", wn.synsets(\"fire\")[0],wn.synsets(\"fire\")[0].definition())\n",
    "print(\"Definition of first fire as verb:\", wn.synsets(\"fire\", pos=wn.VERB)[0],wn.synsets(\"fire\", pos=wn.VERB)[0].definition())\n",
    "\n",
    "# all lemmas for a given synset\n",
    "lemmas=[lemma.name() for lemma in wn.synsets(\"fire\", pos=wn.VERB)[0].lemmas()]\n",
    "print(\"Lemmas\", lemmas, \"\\n\")\n",
    "\n",
    "# List all languages available\n",
    "print(\"Languages available:\",wn.langs(), \"\\n\")\n",
    "\n",
    "# and Finnish lemmas for the same synset, note that we are still using the same 'English' synset\n",
    "lemmas=[lemma for lemma in wn.synsets(\"fire\", pos=wn.VERB)[0].lemma_names(\"fin\")]\n",
    "print(\"Finnish lemmas:\", lemmas, \"\\n\")\n",
    "# ...but we can also use Finnish words\n",
    "print(\"Looked up in Finnish\", wn.synsets(\"tuli\", lang=\"fin\")[0].lemma_names(\"fin\"), \"\\n\")\n",
    "\n",
    "# how many words wordnet has?\n",
    "all_lemmas=[l for l in wn.all_lemma_names(lang=\"eng\")]\n",
    "print(\"First few lemmas\", all_lemmas[:5])\n",
    "print(\"Total words English:\",len(all_lemmas), \"\\n\")\n",
    "\n",
    "\n",
    "# Finnish\n",
    "all_lemmas=[l for l in wn.all_lemma_names(lang=\"fin\")]\n",
    "print(\"First few lemmas in Finnish\", all_lemmas[:5])\n",
    "print(\"Total words Finnish:\",len(all_lemmas))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### synonym lists\n",
    "\n",
    "- now we can use these WordNet synsets to collect a list of synonyms for each word\n",
    "- ...and these synonyms can be used to expand queries\n",
    "- but must keep in mind that these are lemmas, not wordforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finnish: \n",
      "\n",
      "Original query: ['kissa', 'maukua'] \n",
      "\n",
      "Expanded query: ['Felis_catus', 'Felis_domesticus', 'iso_kissaeläin', 'kilpikonnakuvioinen_kissa', 'kissa', 'kissaeläin', 'kotikissa', 'maukua', 'naukua'] \n",
      "\n",
      "\n",
      "English: \n",
      "\n",
      "Original query: ['house', 'flames'] \n",
      "\n",
      "Expanded query: ['business_firm', 'domiciliate', 'family', 'fire', 'firm', 'flame', 'flames', 'flaming', 'flare', 'home', 'house', 'household', 'mansion', 'menage', 'planetary_house', 'put_up', 'sign', 'sign_of_the_zodiac', 'star_sign', 'theater', 'theatre'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def expand_words(words, lang):\n",
    "    # function to expand a list of words using wordnet synsets\n",
    "    synonyms=[]\n",
    "    synonyms+=words\n",
    "    for w in words:\n",
    "        for s in wn.synsets(w, lang=lang):\n",
    "            synonyms+=s.lemma_names(lang)\n",
    "    return set(synonyms)\n",
    "\n",
    "print(\"Finnish:\", \"\\n\")\n",
    "search_words=[\"kissa\", \"maukua\"]\n",
    "print(\"Original query:\", search_words, \"\\n\")\n",
    "expanded=expand_words(search_words,\"fin\")\n",
    "print(\"Expanded query:\", sorted(expanded), \"\\n\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"English:\", \"\\n\")\n",
    "search_words=[\"house\", \"flames\"]\n",
    "print(\"Original query:\", search_words, \"\\n\")\n",
    "expanded=expand_words(search_words,\"eng\")\n",
    "print(\"Expanded query:\", sorted(expanded), \"\\n\")\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synonym expansion in Solr\n",
    "\n",
    "* https://cwiki.apache.org/confluence/display/solr/Filter+Descriptions#FilterDescriptions-SynonymFilter\n",
    "* Looks like we will need a file with synsets like such: *car,vehicle,automobile*  - one per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"synonyms_fin.txt\",\"w\") as f:\n",
    "    for s in wn.all_synsets():\n",
    "        finnish_lemmas=s.lemma_names(\"fin\")\n",
    "        if len(finnish_lemmas)>1: # at least two, would make no sense otherwise\n",
    "            #print them with commas in between, and underscores replaced with spaces\n",
    "            print(\",\".join(l.replace(\"_\",\" \") for l in finnish_lemmas),file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Solr\n",
    "\n",
    "* Here's the default definition of `text_en`\n",
    "\n",
    "```\n",
    "  <fieldType name=\"text_en\" class=\"solr.TextField\" positionIncrementGap=\"100\">\n",
    "    <analyzer type=\"index\">\n",
    "      <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n",
    "      <filter class=\"solr.StopFilterFactory\" words=\"lang/stopwords_en.txt\" ignoreCase=\"true\"/>\n",
    "      <filter class=\"solr.LowerCaseFilterFactory\"/>\n",
    "      <filter class=\"solr.EnglishPossessiveFilterFactory\"/>\n",
    "      <filter class=\"solr.KeywordMarkerFilterFactory\" protected=\"protwords.txt\"/>\n",
    "      <filter class=\"solr.PorterStemFilterFactory\"/>\n",
    "    </analyzer>\n",
    "    <analyzer type=\"query\">\n",
    "      <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n",
    "      <filter class=\"solr.SynonymFilterFactory\" expand=\"true\" ignoreCase=\"true\" synonyms=\"synonyms.txt\"/>\n",
    "      <filter class=\"solr.StopFilterFactory\" words=\"lang/stopwords_en.txt\" ignoreCase=\"true\"/>\n",
    "      <filter class=\"solr.LowerCaseFilterFactory\"/>\n",
    "      <filter class=\"solr.EnglishPossessiveFilterFactory\"/>\n",
    "      <filter class=\"solr.KeywordMarkerFilterFactory\" protected=\"protwords.txt\"/>\n",
    "      <filter class=\"solr.PorterStemFilterFactory\"/>\n",
    "    </analyzer>\n",
    "  </fieldType>\n",
    "```\n",
    "\n",
    "* `text_en` has a differnt pipeline for *query* and *index*\n",
    "* **Index time**\n",
    "  1. Tokenize\n",
    "  2. Filter stop words\n",
    "  3. Lowercase\n",
    "  4. Remove possessive markers\n",
    "  5. Protect some words from stemming\n",
    "  6. Stem\n",
    "* **Query time**\n",
    "  1. Tokenize\n",
    "  2. **Expand synonyms**\n",
    "  3. Filter stop words\n",
    "  4. Lowercase\n",
    "  5. Remove possessive markers\n",
    "  6. Proteict some words from stemming\n",
    "  7. Stem\n",
    "\n",
    "### Query time vs index time is an important distinction\n",
    "\n",
    "* Index time: processing carried out when indexing the data to search\n",
    "* Query time: processing carried out on every query\n",
    "* Certain steps are only needed at query time, certain steps are done on index time\n",
    "* Synonym expansion: maybe not too smart on index time --- why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Word2vec\n",
    "\n",
    "- \"Similar words appear in similar contexts\"\n",
    "- https://github.com/tmikolov/word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kissa: [(0.88850498, 'kani'), (0.8579123, 'kissanpentu'), (0.85663795, 'pentu'), (0.8336221, 'marsu'), (0.80795115, 'katti'), (0.80793911, 'hamsteri'), (0.8023504, 'koira'), (0.798271, 'kisu'), (0.78334367, 'kirppu'), (0.77792805, 'susi')] \n",
      "\n",
      "maukuu: [(0.8782531, 'naukui'), (0.8746469, 'maukui'), (0.86840028, 'naukaisi'), (0.80436617, 'sähisi'), (0.80063224, 'kolli'), (0.79289144, 'sähähti'), (0.78519303, 'murisi'), (0.76773942, 'murahti'), (0.75686067, 'naaras'), (0.75560999, 'sihahti')] \n",
      "\n",
      "ready\n"
     ]
    }
   ],
   "source": [
    "import lwvlib # https://github.com/fginter/wvlib_light\n",
    "\n",
    "model=lwvlib.load(\"/home/jmnybl/pb34_wf_200_v2_skgram.bin\",100000,500000)\n",
    "print(\"kissa:\", model.nearest(\"kissa\"), \"\\n\")\n",
    "print(\"maukuu:\", model.nearest(\"maukuu\"), \"\\n\") # note that these does not have to be base forms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Spelling error expansion\n",
    "\n",
    "* We all know and love Google's \"Did you mean?\" corrections\n",
    "* User query logs a goldmine here - spelling errors can be gathered from logs by looking for queries submitted one after another, with a tiny difference\n",
    "* To my understanding, this is what actually happens\n",
    "* We don't have query logs - let us try to achieve something like this with our means\n",
    "\n",
    "* Head to http://bionlp-www.utu.fi/wv_demo/ - try few Finnish typos\n",
    "* The correct form is often nearby\n",
    "* Word2vec models trained on plenty of data for dozens of languages can nowadays be downloaded: https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1989\n",
    "* We could search systematically for words among whose top-N near list is a word which is 1-2 characters away such that the query word is not recognized as a word of the language, while the similar word is\n",
    "\n",
    "* Code: https://github.com/fginter/wv_spellcheck/blob/master/sc.py\n",
    "* The file pairs_initial.filtered has the right stuff:\n",
    "\n",
    "```\n",
    "1.0     vielä   viellä  5339641 14143\n",
    "1.0     vielä   veilä   5339641 656\n",
    "1.0     ollut   olllut  5674748 1305\n",
    "1.0     ollut   olltu   5674748 333\n",
    "1.0     ollut   ollt    5674748 189\n",
    "1.0     mitä    mtä     4623994 410\n",
    "1.0     kaikki  kaiki   4287031 2037\n",
    "1.0     kaikki  kaikkki 4287031 365\n",
    "1.0     olisi   olsi    5395948 1482\n",
    "1.0     olisi   oisi    5395948 6384\n",
    "1.0     olisi   oilisi  5395948 209\n",
    "1.0     mukaan  mukan   4753605 1581\n",
    "1.0     mukaan  mu­kaan 4753605 436\n",
    "1.0     siitä   siittä  4756536 9938\n",
    "1.0     siitä   siintä  4756536 1896\n",
    "1.0     siitä   siiitä  4756536 604\n",
    "1.0     jotka   joitka  4593675 336\n",
    "1.0     jotka   jotaka  4593675 410\n",
    "1.0     jotka   jotak   4593675 369\n",
    "1.0     jotka   jokta   4593675 302\n",
    "1.0     kuitenkin       kuitekin        4130244 3134\n",
    "1.0     tulee   tuleee  4261769 502\n",
    "1.0     jälkeen jäkeen  4281104 1759\n",
    "1.0     jälkeen jäljeen 4281104 414\n",
    "1.0     jälkeen jäleen  4281104 410\n",
    "```\n",
    "\n",
    "* Now we can filter it and turn it into a spelling error dictionary like such:\n",
    "\n",
    "```\n",
    "paluttaa => paluttaa,palauttaa\n",
    "Cantin => Canthin,Cantin,Canth,Canthia\n",
    "tun- => taan,tun-\n",
    "ollukka => ollukaan,ollukka\n",
    "nuosi => nuosi,nousi\n",
    "Aikasempi => Aikasempi,aikaisempi\n",
    "saahaa => saahaa,saatas\n",
    "otakkaan => otakaan,otakkaan\n",
    "kertoopi => kertoo,kertookin,kertoopi\n",
    "yhdssä => yhdessä,yhdssä\n",
    "niitteen => niitteen,niitten\n",
    "Baselissa => Baselissa,Badenissa\n",
    "Australissa => Australiassa,Australissa\n",
    "selkäesti => selkeästi,selvästi,selkäesti\n",
    "tietyyn => tiettyyn,tietyyn\n",
    "etko => etkö,etko,enkö\n",
    "täytee => täyteen,täytee\n",
    "Oylle => oy:lle,Oy:lle,Oylle\n",
    "miän => miän,meikän\n",
    "pienetää => pienetää,pienentää\n",
    "muussina => muussina,muusina\n",
    "rävellystä => rävellystä,räpellystä\n",
    "roopan => roopan,Euroopan\n",
    "niis => jois,niis\n",
    "yhta => yhtä,yhta\n",
    "ajatelen => ajattelen,ajatelen\n",
    "wappuna => wappuna,vappuna,Vappuna\n",
    "TSOP:n => TSOP:n,SOK:n\n",
    "kute => kuten,kute\n",
    "tehosekottimeen => tehosekottimeen,tehosekoittimeen\n",
    "käyti => käyty,käyti,käytti\n",
    "```\n",
    "\n",
    "...and then we can point solr to it in its config like so:\n",
    "\n",
    "```\n",
    "  <fieldType name=\"text_fi\" class=\"solr.TextField\" positionIncrementGap=\"1\">\n",
    "    <analyzer type=\"index\">\n",
    "      <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n",
    "      <filter class=\"solr.LowerCaseFilterFactory\"/>\n",
    "      <filter class=\"solr.SnowballPorterFilterFactory\" language=\"Finnish\"/>\n",
    "    </analyzer>\n",
    "    <analyzer type=\"query\">\n",
    "      <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n",
    "      <filter class=\"solr.SynonymFilterFactory\" expand=\"true\" ignoreCase=\"True\" synonyms=\"spelling_fi.txt\" />\n",
    "      <filter class=\"solr.SynonymFilterFactory\" expand=\"true\" ignoreCase=\"True\" synonyms=\"synonyms_fi_wordnet.txt\" />\n",
    "      <filter class=\"solr.LowerCaseFilterFactory\"/>\n",
    "      <filter class=\"solr.SnowballPorterFilterFactory\" language=\"Finnish\"/>\n",
    "    </analyzer>\n",
    "  </fieldType>\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
